version: "3.9"

# networks
networks:
  frigate:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.name: frigate
    ipam:
      driver: default
      config:
        - subnet: ${SUBNET}/24
          gateway: ${GATEWAY}


# docker managed persistent volumes
volumes:
  config:

services:
  frigate:
    container_name: frigate
# No direct gpu support
#    image: ghcr.io/blakeblackshear/frigate:stable
# For nvidia gpu support, use this instead:
    image: ghcr.io/blakeblackshear/frigate:stable-tensorrt
    hostname: ${FR_HOST}
    domainname: ${DOMAIN}
    privileged: true # this may not be necessary for all setups
    restart: unless-stopped
    stop_grace_period: 30s # allow enough time to shut down the various services
    shm_size: "1024mb" # update for your cameras based on calculation above
# If using nvidia gpu, uncomment below:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      FRIGATE_RTSP_PASSWORD: ${FR_RTSP_PASS} # only needed if using with HASS... I think...
      TZ: ${TZ}
#      YOLO_MODELS:
    networks:
      frigate:
        ipv4_address: ${FR_IP}
    ports:
      - "8971:8971"
      # - "5000:5000" # Internal unauthenticated access. Expose carefully.
      - "8554:8554" # RTSP feeds
      - "8555:8555/tcp" # WebRTC over tcp
      - "8555:8555/udp" # WebRTC over udp
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - config:/config
      - /Frigate:/media/frigate
      - type: tmpfs
        target: /tmp/cache
        tmpfs:
          size: 1000000000